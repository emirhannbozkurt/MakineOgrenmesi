# -*- coding: utf-8 -*-
"""MakinaOgrenmesiProje.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1yKhK6a_JIFBmcFLPeKESydAfcF1WTCgx

# ***Kütüphaneler***
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import plotly.express as px
import seaborn as sns
import itertools

"""# ***Veri Kümesine genel bakış :***"""

train_df=pd.read_csv('/content/train.csv')
test_df=pd.read_csv('/content/test.csv')

#train_df.info()
print('train dataset size:',test_df.shape)
train_df.head()

"""Veri içeriğimizde null yada nan değerlerimiz olup olmadığını kontrol ediyoruz."""

print('null values:',train_df.isnull().values.sum())
train_df.dtypes

train_df.info()

test_df.info()

"""Kontrol sonrası veri kümemiz herhangibir eksik değer içermiyor . Şimdi veri setlerimizde kopyaları kontrol ederek bir sonraki adıma geçiyoruz."""

print('Train setinde ki kopya sayısı:{}'.format(sum(train_df.duplicated())))
print('Test setinde ki kopya sayısı:{}'.format(sum(test_df.duplicated())))
print('Tekrar eden veri:',train_df.duplicated().values.sum())

train_df['subject'].groupby(train_df['subject']).count()

"""Veri setimizde 30 denek vardır ve her biri görevi birkaç kez gerçekleştirmiştir."""

train_df['subject'].groupby(train_df['Activity']).value_counts()

"""Yani 30 deneğimiz var ve her biri farklı denemeler yaptı. Şimdi train veri setimizde her bir aktivitenin kaç kez denendiğine bakalım:"""

# .size() and .count() aynı cevapları sağlar.
train_df['Activity'].groupby(train_df['Activity']).size()

#veri kümesinden sınıf etiketini ayırma

trainLabels= train_df.Activity.values
trainData=train_df.drop("Activity",axis=1).values

testLabels= test_df.Activity.values
testData=test_df.drop("Activity",axis=1).values

from sklearn import preprocessing
labelEncoder= preprocessing.LabelEncoder()

labelEncoder.fit(trainLabels)
trainLabelsE=labelEncoder.transform(trainLabels)

labelEncoder.fit(testLabels)
testLabelsE=labelEncoder.transform(testLabels)

"""# ***Sorun çerçevesi***

*   30 konu var.
*   Veri setinde her veri noktası altı aktiviteden oluşuyor.
*   Her denek etkinliği birkaç kez tekrarlıyor.

Şimdi veri kümesi verildiğinde, özellik kümesine dayalı etkinliği tahmin edebilir miyiz?

Veri dengesizliğini kontrol edin:
"""

px.pie(train_df,names='Activity',title='Veritabanındaki etkinlik')

"""Pasta grafiğine baktığımız zaman verilerin dengeli olduğunu görmekteyiz."""

px.histogram(data_frame=train_df,x='subject',color='Activity',barmode='group',title='Train veri setinin histogramı')

px.histogram(data_frame=test_df,x='subject',color='Activity',barmode='group',title='Test veri setinin histogramı')

"""Gördüğümüz gibi, tüm konulardan neredeyse aynı sayıda okuma aldık."""

px.histogram(train_df,x='Activity',color='Activity',title='Aktivite başına kayıt sayısı')

def plot_confusion_matrix(cm, classes,
                          normalize=False,
                          title='Confusion matrix',
                          cmap=plt.cm.Blues):
    """
    This function prints and plots the confusion matrix.
    Normalization can be applied by setting `normalize=True`.
    """
    plt.imshow(cm, interpolation='nearest', cmap=cmap)
    plt.title(title)
    plt.colorbar()
    tick_marks = np.arange(len(classes))
    plt.xticks(tick_marks, classes, rotation=45)
    plt.yticks(tick_marks, classes)

    if normalize:
        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
        print("Normalized confusion matrix")
    else:
        print('Confusion matrix, without normalization')

    print(cm)

    thresh = cm.max() / 2.
    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):
        plt.text(j, i, cm[i, j],
                 horizontalalignment="center",
                 color="white" if cm[i, j] > thresh else "black")

    plt.tight_layout()
    plt.ylabel('True label')
    plt.xlabel('Predicted label')

"""# ***Veri keşfi***"""

corrmat=train_df.corr()
f,ax=plt.subplots(figsize=(10,10))
sns.heatmap(corrmat,vmax=0.8,square=True)

"""Ortalama ivme büyüklüğünün histogramı, dinamik aktivitelerin statik aktivitelerden farklı olduğunu gösterir."""

px.histogram(train_df,x='tBodyAccMag-mean()',color='Activity')
#sns.displot(train_df,x='tBodyAccMag-mean()',hue='Activity')

px.box(train_df, x='Activity',y='tBodyAccMag-mean()')

"""Özellik uzayımızın çok büyük olduğunu biliyoruz . muhtemelen daha düşük boyutta grupları birbirinden ayırması daha kolay bir başka yöntem bulabiliriz.
PCA ile denemeye başlayalım

"""

from sklearn import preprocessing
X=train_df.drop('Activity',axis=1)
Y=train_df['Activity']
print('X matrix size:',X.shape)
X=preprocessing.StandardScaler().fit(X).transform(X)
#X
X_test=test_df.drop('Activity',axis=1)
X_t=preprocessing.StandardScaler().fit(X_test).transform(X_test)

import numpy as np
from sklearn.decomposition import PCA
import matplotlib.pyplot as plt
pca=PCA(n_components=200).fit(X)   # number of components
principal_component=pca.transform(X)
plt.plot(np.cumsum(pca.explained_variance_ratio_))
plt.xlabel('principal component')
plt.ylabel('explained variance')

"""Değişkenlik açıklamasına dayalı olarak(grafiği yorumlayarak), ilk 50 bileşen veri kümesindeki değişkenliğin %90'ından fazlasını açıklayabileceğini görmekteyiz . İlk 50 bileşen, sınıflandırma için kullanılmak üzere seçiyoruz."""

principal_component=PCA(n_components=200).fit_transform(X)
X_test_pca=pca.transform(X_t)
#,columns=['Comp1','Comp2','Comp3']
pca_df=pd.DataFrame(data=principal_component)
pca_test_d=pd.DataFrame(data=X_test_pca)
pca_df.head()
pca_df.shape

import plotly.express as px
px.scatter(x=pca_df[3],y=pca_df[2],color=train_df['Activity'])

"""Şimdi yüksek boyutlu verilerimizi görselleştirmek için lineer olmayan boyut indirgeme ve görselleştirme yöntemi olan t-SNE'yi kullanalım:

# ***Verilere t-SNE uygulama :***
"""

from sklearn.manifold import TSNE
import seaborn as sns

# perform t-sne with different preplexities and their plots
def perform_tsne(X_data, y_data, perplexities, n_iter=1000, img_name_prefix='t-sne'):
        
    for index,perplexity in enumerate(perplexities):
        # t-SNE yapıyoruz
        print('\nperforming tsne with perplexity {} and with {} iterations at max'.format(perplexity, n_iter))
        X_reduced = TSNE(verbose=2, perplexity=perplexity).fit_transform(X_data)
        print('Done..')
        
        # prepare the data for seaborn         
        print('Creating plot for this t-sne visualization..')
        df = pd.DataFrame({'x':X_reduced[:,0], 'y':X_reduced[:,1] ,'label':y_data})
        
        # draw the plot in appropriate place in the grid
        sns.lmplot(data=df, x='x', y='y', hue='label', fit_reg=False, size=8,\
                   palette="Set1",markers=['^','v','s','o', '1','2'])
        plt.title("perplexity : {} and max_iter : {}".format(perplexity, n_iter))
        img_name = img_name_prefix + '_perp_{}_iter_{}.png'.format(perplexity, n_iter)
        print('saving this plot as image in present working directory...')
        plt.savefig(img_name)
        plt.show()
        print('Done')

X_pre_tsne = train_df.drop(['subject', 'Activity'], axis=1)
y_pre_tsne = train_df['Activity']
perform_tsne(X_data = X_pre_tsne,y_data=y_pre_tsne, perplexities =[5,10,20])

"""Görselleştirmeye baktığımız zaman ayakta durmak ve oturmak, modelimizin ayırmakta en çok zorlanacağı iki aktivite.

Artık sahip olduğumuz bilgilerle, verileri sınıflandırmak için farklı sınıflandırma tekniklerini kullanmaya devam edebiliriz. kullanacağız:



1.   Lojistik regresyon
2.   SWM
3.   Karar ağacı

# ***Lojistik regresyon***
"""

X_train=train_df.drop('Activity',axis=1)
Y_train=train_df['Activity']
X_test=test_df.drop('Activity',axis=1)
Y_test=test_df['Activity']

from sklearn.linear_model import LogisticRegression
lr_clf=LogisticRegression(C=0.01,solver='liblinear')
lr_clf.fit(X_train,Y_train)

from sklearn.metrics import classification_report,accuracy_score
y_hat=lr_clf.predict(X_test)
print('doğruluk puanı(test verileri): \n',accuracy_score(Y_test,y_hat))
print('Sınıflandırma raporu (test veri seti): \n',classification_report(Y_test,y_hat))

"""**Karışıklık matrisi**"""

from sklearn.metrics import accuracy_score
from sklearn.metrics import f1_score,confusion_matrix,classification_report,ConfusionMatrixDisplay
cm = confusion_matrix(Y_test,y_hat, labels=lr_clf.classes_)
disp= ConfusionMatrixDisplay(confusion_matrix=cm,display_labels=lr_clf.classes_)
fig, ax = plt.subplots(figsize=(20,20))
disp.plot(ax=ax)

"""Şimdi PCA özellikleriyle lojistik regresyon yapalım:"""

lr_pca=LogisticRegression(C=0.01,solver='liblinear')
lr_pca.fit(pca_df,Y_train)
pca_pre=lr_pca.predict(pca_test_d)
print('Sınıflandırma raporu (LR PCA özellikleri)\n',classification_report(pca_pre,Y_test))

"""Sonuçlara göre, model PCA verilerinde, eşdoğrusallığın kaldırıldığı ve tüm özelliklerin ortonormal en iyi performansta olduğunu gösteriyor."""

cm = confusion_matrix(Y_test,pca_pre, labels=lr_pca.classes_)
disp= ConfusionMatrixDisplay(confusion_matrix=cm,display_labels=lr_pca.classes_)
fig, ax = plt.subplots(figsize=(20,20))
disp.plot(ax=ax)

"""# ***SVM***"""

from sklearn import svm
#SVM kernel: ‘linear’, ‘poly’, ‘rbf’, ‘sigmoid’, ‘precomputed’
svm_clf=svm.SVC(kernel='rbf')
svm_clf.fit(X_train,Y_train)
y_hat=svm_clf.predict(X_test)
print('SVM doğruluk puanı (test verileri):\n',accuracy_score(Y_test,y_hat))
print('SVM sınıflandırma raporu (test verileri): \n',classification_report(Y_test,y_hat))

"""**Karışıklık** **matrisi**"""

cm = confusion_matrix(Y_test,y_hat, labels=svm_clf.classes_)
disp= ConfusionMatrixDisplay(confusion_matrix=cm,display_labels=svm_clf.classes_)
fig, ax = plt.subplots(figsize=(20,20))
disp.plot(ax=ax)

"""# ***Karar ağacı sınıflandırıcı***"""

from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score,confusion_matrix

decsnTreeClf= DecisionTreeClassifier(criterion='entropy')
tree=decsnTreeClf.fit(trainData,trainLabelsE)
testPred=tree.predict(testData)

acc= accuracy_score(testLabelsE,testPred)
cfs = confusion_matrix(testLabelsE, testPred)

print("Kesinlik: %f" %acc)

plt.figure()
class_names = labelEncoder.classes_
plot_confusion_matrix(cfs, classes=class_names,
                      title='DecisionTree Karışıklık Matrisi')